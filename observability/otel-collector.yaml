# OpenTelemetry Collector Configuration — brAIn
# Receives traces/metrics/logs from all modules and exports to local backends.
#
# Receivers:  OTLP (gRPC + HTTP)
# Processors: batch, memory_limiter
# Exporters:  prometheus (metrics), logging (debug), otlp (traces → Jaeger/Tempo)

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  batch:
    timeout: 5s
    send_batch_size: 1024

  # Attach service metadata for easier Grafana filtering
  resource:
    attributes:
      - key: deployment.environment
        value: "local"
        action: upsert
      - key: service.namespace
        value: "brain"
        action: upsert

exporters:
  # Expose scraped metrics for Prometheus
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: brain

  # Structured console output for local development
  debug:
    verbosity: normal

  # Forward traces to Jaeger or Grafana Tempo (wire in production)
  # otlp/tempo:
  #   endpoint: tempo:4317
  #   tls:
  #     insecure: true

service:
  telemetry:
    logs:
      level: warn

  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [debug]

    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [prometheus, debug]

    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [debug]
